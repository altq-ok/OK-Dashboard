"""
FastAPI Application Entry Point.

Handles the lifecycle of the background worker process and provides
REST endpoints for the Next.js frontend to interact with the calculation engine.
"""

import logging
import os
from contextlib import asynccontextmanager
from datetime import datetime, timezone
from multiprocessing import Process, Queue
from os.path import expanduser

from fastapi import FastAPI, HTTPException, Request
from starlette.middleware.cors import CORSMiddleware

from app.core.data_manager import DataManager
from app.core.status import StatusManager
from app.core.syncer import FileSyncer
from app.core.worker import calc_worker
from app.schemas.task import TaskParams, TaskStatus

logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)


# Configuration
home = expanduser("~")
SHARED_DIR = f"{home}\\Dev\\TypeScript\\Shared"
LOCAL_DIR = f"{home}\\Dev\\TypeScript\\Local"
USER_NAME = os.getlogin()

# To save under app.state
state = {}


@asynccontextmanager
async def lifespan(app: FastAPI):
    """
    Lifecycle handler to manage startup and shutdown of FastAPI
    Before yield => on startup
    After yield => on shutdown
    """
    # Initialize managers
    # StatusManager and DataManager will monitor local mirror of shared
    app.state.status_manager = StatusManager(LOCAL_DIR)
    app.state.data_manager = DataManager(LOCAL_DIR)

    # Start file syncer thread
    syncer = FileSyncer(SHARED_DIR, LOCAL_DIR, interval=5)
    syncer.start()
    app.state.syncer = syncer

    # Start a worker process
    task_queue = Queue()  # Queue for IPC between FastAPI and Worker
    worker_process = Process(target=calc_worker, args=(task_queue, SHARED_DIR, USER_NAME), daemon=True)
    worker_process.start()

    # Save them to app.state, so each API endpoint can access
    app.state.task_queue = task_queue
    app.state.worker_process = worker_process

    logger.info(f"Worker process started with PID {worker_process.pid}")

    yield  # FastAPI starts up here and wait for a request

    # Cleanup on FastAPI's shutdown
    logger.info("Worker process shutting down. Cleaning up resources...")
    if app.state.worker_process.is_alive():
        app.state.worker_process.terminate()
        app.state.worker_process.join()

    # Stop syncer's thread
    if hasattr(app.state.syncer, "stop"):
        app.state.syncer.stop()

    logger.info("Worker process cleanup complete")


# Set lifespan on app creation
app = FastAPI(lifespan=lifespan)

# CORS to allow an access from frontend
app.add_middleware(CORSMiddleware, allow_origins=["http://localhost:3000"], allow_methods=["*"], allow_headers=["*"])


@app.post("/run-task")
async def run_task(params: TaskParams, request: Request):
    """
    Submits a task to the local worker queue.
    The task_id is generated by combining target_id and task_type.
    """
    task_id = f"{params.target_id}_{params.task_type}"
    try:
        request.app.state.task_queue.put(
            {
                "task_id": task_id,
                "params": params.model_dump(),  # Convert Pydantic to dict for Queue
            }
        )
        return {"status": "accepted", "task_id": task_id}
    except Exception as e:
        logger.error(f"Failed to submit task: {e}")
        raise HTTPException(status_code=500, detail="Internal worker queue error")


@app.get("/tasks/status", response_model=list[TaskStatus])
async def get_all_task_statuses(request: Request):
    """
    Returns the status of all tracked tasks in the team's shared directory.
    Used by the Global Task Monitor (Dropdown).
    """
    return request.app.state.status_manager.get_all_statuses()


@app.get("/tasks/{target_id}/{task_type}/status", response_model=TaskStatus)
async def get_task_status(target_id: str, task_type: str, request: Request):
    """
    Returns status for a specific task. Used for widget-level polling.
    """
    task_id = f"{target_id}_{task_type}"
    # Get status from local mirror
    status = request.app.state.status_manager.get_status(task_id)
    if not status:
        raise HTTPException(status_code=404, detail="Task status not found")
    return status


@app.get("/tasks/{target_id}/{task_type}/snapshots")
async def get_task_snapshots(target_id: str, task_type: str, request: Request):
    """
    Returns a list of available parquet snapshot filenames for a task.
    """
    snapshots = request.app.state.data_manager.get_snapshots(task_type, target_id)
    return {"snapshots": snapshots}


@app.get("/tasks/{target_id}/{task_type}/data")
async def get_task_data(target_id: str, task_type: str, request: Request, version: str = "latest"):
    """
    Returns the actual content of a parquet snapshot as a JSON-serializable list.
    Supports historical data retrieval via the 'version' query parameter.
    """
    data_manager = request.app.state.data_manager
    try:
        if version == "latest":
            data = data_manager.get_latest_data(task_type, target_id)
        else:
            df = data_manager.load_parquet(task_type, target_id, version)
            data = df.to_dict(orient="records")
        return {"data": data}
    except FileNotFoundError:
        raise HTTPException(status_code=404, detail="Snapshot file not found")
    except Exception as e:
        logger.error(f"Error reading parquet: {e}")
        raise HTTPException(status_code=500, detail="Error processing data file")


@app.post("/stop-worker")
async def stop_worker(request: Request):
    """
    Manually restarts the worker process to clear memory or recover from hangs.
    """
    if request.app.state.worker_process.is_alive():
        request.app.state.worker_process.terminate()
        request.app.state.worker_process.join()

    # Re-spawn the process with the existing queue
    new_process = Process(target=calc_worker, args=(request.app.state.task_queue, SHARED_DIR, USER_NAME), daemon=True)
    new_process.start()
    request.app.state.worker_process = new_process

    return {"status": "restarted", "new_pid": new_process.pid}


@app.get("/health")
async def health_check():
    """Simple API health check with basic metadata."""
    return {
        "status": "ok",
        "user": USER_NAME,
        "timestamp_utc": datetime.now(timezone.utc).isoformat(),
    }
